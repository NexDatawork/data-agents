{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48250b17-aada-4838-8fe9-843fe970b904",
      "metadata": {
        "id": "48250b17-aada-4838-8fe9-843fe970b904"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from IPython.display import Markdown, HTML, display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "146be3c7-90df-4fbe-bff6-00166f3d61d2",
      "metadata": {
        "id": "146be3c7-90df-4fbe-bff6-00166f3d61d2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Replace with your actual values\n",
        "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"INSERT THE OPENAI ENDPOINT\"\n",
        "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"INSERT YOUR OPENAI API KEY\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5e1b596-4568-4078-ae14-b20d25cba62b",
      "metadata": {
        "id": "f5e1b596-4568-4078-ae14-b20d25cba62b"
      },
      "outputs": [],
      "source": [
        "# 2nd Cell: Azure OpenAI setup\n",
        "import os\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "\n",
        "# Load your Azure environment variables\n",
        "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
        "AZURE_DEPLOYMENT_NAME = \"gpt-4.1\"  # üëà Change if needed\n",
        "AZURE_API_VERSION = \"2025-01-01-preview\"  # üëà Use your correct version\n",
        "\n",
        "# Define Azure LLM with streaming enabled\n",
        "model = AzureChatOpenAI(\n",
        "    openai_api_version=AZURE_API_VERSION,\n",
        "    azure_deployment=AZURE_DEPLOYMENT_NAME,\n",
        "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
        "    streaming=True,\n",
        "    callbacks=[StreamingStdOutCallbackHandler()],\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "789b46d9-2189-4d3c-8f77-61b4675bf950",
      "metadata": {
        "id": "789b46d9-2189-4d3c-8f77-61b4675bf950"
      },
      "outputs": [],
      "source": [
        "# --- Setup ---\n",
        "import os\n",
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import io\n",
        "import contextlib\n",
        "\n",
        "from langchain.agents.agent_types import AgentType\n",
        "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
        "\n",
        "# Replace this with your actual LLM setup\n",
        "# Example:\n",
        "# from langchain_openai import AzureChatOpenAI\n",
        "# model = AzureChatOpenAI(...)\n",
        "\n",
        "# Prompt\n",
        "CSV_PROMPT_PREFIX = \"\"\"\n",
        "Set pandas to show all columns.\n",
        "Get the column names and infer data types.\n",
        "Then attempt to answer the question using multiple methods.\n",
        "Please provide only the Python code required to perform the action, and nothing else.\n",
        "\"\"\"\n",
        "\n",
        "CSV_PROMPT_SUFFIX = \"\"\"\n",
        "- Try at least 2 different methods of calculation or filtering.\n",
        "- Reflect: Do they give the same result?\n",
        "- After performing all necessary actions and analysis with the dataframe, return the answer in clean **Markdown**, include summary table if needed.\n",
        "- Include **Execution Recommendation** and **Web Insight** in the final Markdown.\n",
        "- Always conclude the final Markdown with:\n",
        "\n",
        "### Final Answer\n",
        "\n",
        "Your conclusion here.\n",
        "\n",
        "---\n",
        "\n",
        "### Explanation\n",
        "\n",
        "Mention specific columns you used.\n",
        "Please provide only the Python code required to perform the action, and nothing else until the final Markdown output.\n",
        "\"\"\"\n",
        "\n",
        "# --- Agent Logic ---\n",
        "def ask_agent(files, question):\n",
        "    try:\n",
        "        dfs = [pd.read_csv(f.name) for f in files]\n",
        "        df = pd.concat(dfs, ignore_index=True)\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Could not read CSVs: {e}\", \"\"\n",
        "\n",
        "    try:\n",
        "        agent = create_pandas_dataframe_agent(\n",
        "        llm=model,\n",
        "        df=df,\n",
        "        verbose=True,\n",
        "        agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "        allow_dangerous_code=True,\n",
        "        handle_parsing_errors=True,  # üëà this is the fix\n",
        "    )\n",
        "\n",
        "\n",
        "        full_prompt = CSV_PROMPT_PREFIX + question + CSV_PROMPT_SUFFIX\n",
        "\n",
        "        buffer = io.StringIO()\n",
        "        with contextlib.redirect_stdout(buffer):\n",
        "            result = agent.invoke(full_prompt)\n",
        "        trace = buffer.getvalue()\n",
        "        output = result[\"output\"]\n",
        "\n",
        "\n",
        "        return output, trace\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Agent error: {e}\", \"\"\n",
        "\n",
        "# --- Gradio UI ---\n",
        "with gr.Blocks(\n",
        "    css=\"\"\"\n",
        "    body, .gradio-container {\n",
        "        background: #ffffff !important;\n",
        "        color: #1f2937 !important;\n",
        "        font-family: 'Segoe UI', sans-serif;\n",
        "    }\n",
        "\n",
        "    #title {\n",
        "        color: #1f2937 !important;\n",
        "        font-size: 2rem;\n",
        "        font-weight: 600;\n",
        "        text-align: center;\n",
        "        padding-top: 20px;\n",
        "        padding-bottom: 10px;\n",
        "    }\n",
        "\n",
        "    .gr-box, .gr-input, .gr-output, .gr-markdown, .gr-textbox, .gr-file, textarea, input {\n",
        "        background: rgba(0, 0, 0, 0.04) !important;\n",
        "        border: 1px solid rgba(0, 0, 0, 0.1);\n",
        "        border-radius: 12px !important;\n",
        "        color: #1f2937 !important;\n",
        "    }\n",
        "\n",
        "    textarea::placeholder, input::placeholder {\n",
        "        color: rgba(31, 41, 55, 0.6) !important;\n",
        "    }\n",
        "\n",
        "    button {\n",
        "        background: rgba(0, 0, 0, 0.07) !important;\n",
        "        color: #1f2937 !important;\n",
        "        border: 1px solid rgba(0, 0, 0, 0.15) !important;\n",
        "        border-radius: 8px !important;\n",
        "    }\n",
        "\n",
        "    button:hover {\n",
        "        background: rgba(0, 0, 0, 0.15) !important;\n",
        "    }\n",
        "    \"\"\"\n",
        ") as demo:\n",
        "\n",
        "    gr.Markdown(\"<h2 id='title'>üìä NexDatawork Data Agent</h2>\")\n",
        "\n",
        "    with gr.Column():\n",
        "        result_display = gr.Markdown(label=\"üìå Report Output (Markdown)\")\n",
        "        trace_display = gr.Textbox(label=\"üõ†Ô∏è Data Agent Reasoning - Your Explainable Agent\", lines=20)\n",
        "\n",
        "    with gr.Row(equal_height=True):\n",
        "        file_input = gr.File(label=\"üìÅ Upload CSV(s)\", file_types=[\".csv\"], file_count=\"multiple\")\n",
        "        question_input = gr.Textbox(\n",
        "    label=\"üí¨ Ask Your Data\",\n",
        "    placeholder=\"e.g., What is the trend for revenue over time?\",\n",
        "    lines=9\n",
        ")\n",
        "\n",
        "\n",
        "    ask_button = gr.Button(\"üí° Analyze\")\n",
        "\n",
        "    ask_button.click(\n",
        "        fn=ask_agent,\n",
        "        inputs=[file_input, question_input],\n",
        "        outputs=[result_display, trace_display]\n",
        "    )\n",
        "\n",
        "demo.launch(share=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fM4cO6jTgXlu"
      },
      "id": "fM4cO6jTgXlu",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10 (LangChain)",
      "language": "python",
      "name": "langchain310"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}