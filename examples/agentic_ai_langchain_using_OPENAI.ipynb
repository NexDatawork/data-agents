{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bb9fdc0",
   "metadata": {},
   "source": [
    "# Simplified Fintech Agentic AI \n",
    "\n",
    "1. Identity: role, guardrails, run_id / agent_id / versions  \n",
    "2. Logic: ReAct loop (tool calls + observations)  \n",
    "3. Optimization: Python tool for all numeric calculations  \n",
    "4. Workflow: Human-in-the-loop trigger -> `Needs Human Review`  \n",
    "5. Reliability: decision records + backtesting stub\n",
    "\n",
    "To run: set `OPENAI_API_KEY` in your environment, or paste it when prompted in the first code cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df40a00",
   "metadata": {},
   "source": [
    "## 0) Install \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cf5bbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run once if needed\n",
    "# !pip install -U langchain langchain-openai langchain-experimental langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd98e53",
   "metadata": {},
   "source": [
    "## 1) API Key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54de27f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"API-KEY-HERE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d948bc3",
   "metadata": {},
   "source": [
    "## 2) Identity - Governance Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66f4f7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KPdesktop\\AppData\\Local\\Temp\\ipykernel_16888\\189987188.py:34: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  \"run_id\": f\"run_{datetime.datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}_{uuid.uuid4().hex[:8]}\",\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'run_id': 'run_20260224T042158Z_4e148164',\n",
       " 'agent_id': 'credit_risk_agent',\n",
       " 'model_version': 'gpt-4o-mini',\n",
       " 'policy_version': 'v1.0'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json, uuid, datetime\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "AGENT_ID = \"credit_risk_agent\"\n",
    "POLICY_VERSION = \"v1.0\"\n",
    "MODEL_VERSION = os.getenv(\"MODEL_VERSION\", \"gpt-4o-mini\")\n",
    "\n",
    "NEGATIVE_CONSTRAINTS = [\n",
    "    \"Never provide legal advice.\",\n",
    "    \"Never provide investment advice or guaranteed outcomes.\",\n",
    "    \"Never request or store personal identifiers (name, address, SSN, account numbers).\",\n",
    "    \"Never fabricate tool outputs or numeric results.\",\n",
    "    \"Never compute financial math in free text; always use tools.\",\n",
    "    \"If inputs are missing or invalid, ask for correction instead of guessing.\",\n",
    "    \"If case is high impact or high risk, output 'Needs Human Review'.\",\n",
    "]\n",
    "\n",
    "SYSTEM_ROLE = f'''\n",
    "You are a financial risk assistant.\n",
    "Your job is to draft risk assessments based on approved tools and approved, non-sensitive inputs.\n",
    "\n",
    "Hard rules:\n",
    "- {chr(10).join('- ' + x for x in NEGATIVE_CONSTRAINTS)}\n",
    "\n",
    "Output format (always):\n",
    "- Header: run_id, agent_id, model_version, policy_version\n",
    "- Decision: \"Decision Draft\" or \"Needs Human Review\"\n",
    "- Evidence: tool used + inputs summary + computed risk score + threshold comparison\n",
    "- Short rationale (1-2 lines)\n",
    "'''.strip()\n",
    "\n",
    "def new_run_metadata() -> Dict[str, str]:\n",
    "    return {\n",
    "        \"run_id\": f\"run_{datetime.datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}_{uuid.uuid4().hex[:8]}\",\n",
    "        \"agent_id\": AGENT_ID,\n",
    "        \"model_version\": MODEL_VERSION,\n",
    "        \"policy_version\": POLICY_VERSION,\n",
    "    }\n",
    "\n",
    "run_meta = new_run_metadata()\n",
    "run_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329a7c63",
   "metadata": {},
   "source": [
    "## 3) Optimization - Tooling Layer (Python tool for all numeric work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ba14b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "\n",
    "python_repl = PythonREPL()\n",
    "\n",
    "@tool\n",
    "def python_scoring(python_code: str) -> str:\n",
    "    '''\n",
    "    Execute python code for scoring/stat checks.\n",
    "    Expected behavior: python_code should set a variable named `result` as a JSON string, then print(result).\n",
    "    '''\n",
    "    return python_repl.run(python_code)\n",
    "\n",
    "tools = [python_scoring]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91fa39c",
   "metadata": {},
   "source": [
    "## 4) Workflow - Orchestration Layer (HITL trigger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef64f184",
   "metadata": {},
   "outputs": [],
   "source": [
    "RISK_THRESHOLD = 0.50\n",
    "HIGH_IMPACT_AMOUNT = 1_000_000  # example\n",
    "\n",
    "def build_query(income: float, debt: float, credit_score: int, requested_amount: float) -> str:\n",
    "    return f'''\n",
    "Use the python_scoring tool ONLY. Do not do math in text.\n",
    "\n",
    "Inputs:\n",
    "income = {income}\n",
    "debt = {debt}\n",
    "credit_score = {credit_score}\n",
    "requested_amount = {requested_amount}\n",
    "\n",
    "Risk formula:\n",
    "risk = (debt/income * 0.6) + ((850-credit_score)/850 * 0.4)\n",
    "\n",
    "Write Python code that:\n",
    "1) computes risk\n",
    "2) creates a dict named payload with keys: risk_score, threshold, high_impact, reason_codes, evidence\n",
    "3) sets a variable named result = json.dumps(payload)\n",
    "4) prints(result)\n",
    "'''.strip()\n",
    "\n",
    "def parse_json_from_text(text: str) -> Dict[str, Any]:\n",
    "    import re, json\n",
    "    m = re.search(r\"\\{.*\\}\", text, flags=re.S)\n",
    "    if not m:\n",
    "        return {}\n",
    "    try:\n",
    "        return json.loads(m.group(0))\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "def apply_hitl_policy(result_json: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    risk = float(result_json.get(\"risk_score\", 0.0))\n",
    "    high_impact = bool(result_json.get(\"high_impact\", False))\n",
    "    reason_codes = list(result_json.get(\"reason_codes\", []))\n",
    "\n",
    "    needs_review = False\n",
    "    if risk > RISK_THRESHOLD:\n",
    "        needs_review = True\n",
    "        if \"HIGH_RISK_SCORE\" not in reason_codes:\n",
    "            reason_codes.append(\"HIGH_RISK_SCORE\")\n",
    "    if high_impact:\n",
    "        needs_review = True\n",
    "        if \"HIGH_IMPACT_CASE\" not in reason_codes:\n",
    "            reason_codes.append(\"HIGH_IMPACT_CASE\")\n",
    "\n",
    "    decision = \"Needs Human Review\" if needs_review else \"Decision Draft\"\n",
    "    return {\n",
    "        \"decision\": decision,\n",
    "        \"risk_score\": risk,\n",
    "        \"threshold\": RISK_THRESHOLD,\n",
    "        \"high_impact\": high_impact,\n",
    "        \"reason_codes\": reason_codes,\n",
    "        \"evidence\": result_json.get(\"evidence\", {}),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c2b9f8",
   "metadata": {},
   "source": [
    "## 5) Logic -  agent (LangGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a64c5da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KPdesktop\\AppData\\Local\\Temp\\ipykernel_16888\\3723743553.py:5: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
      "  graph_agent = create_react_agent(llm, tools)\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "llm = ChatOpenAI(model=MODEL_VERSION, temperature=0)\n",
    "graph_agent = create_react_agent(llm, tools)\n",
    "print(\"Agent created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfbbd9d",
   "metadata": {},
   "source": [
    "## 6) Run one case (end-to-end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc682183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RAW AGENT OUTPUT ===\n",
      "- Header: run_id: run_20260224T042158Z_4e148164, agent_id: credit_risk_agent, model_version: gpt-4o-mini, policy_version: v1.0\n",
      "- Decision: \"Decision Draft\"\n",
      "- Evidence: tool used: python_scoring + inputs summary: income=75000, debt=30000, credit_score=620, requested_amount=250000 + computed risk score: 0.3482 + threshold comparison: risk score (0.3482) is below threshold (0.5)\n",
      "- Short rationale: The computed risk score indicates a low risk, as it is below the established threshold.\n",
      "\n",
      "=== FINAL STRUCTURED OUTPUT ===\n",
      "{\n",
      "  \"run_id\": \"run_20260224T042158Z_4e148164\",\n",
      "  \"agent_id\": \"credit_risk_agent\",\n",
      "  \"model_version\": \"gpt-4o-mini\",\n",
      "  \"policy_version\": \"v1.0\",\n",
      "  \"decision\": \"Decision Draft\",\n",
      "  \"risk_score\": 0.0,\n",
      "  \"threshold\": 0.5,\n",
      "  \"high_impact\": false,\n",
      "  \"reason_codes\": [],\n",
      "  \"evidence\": {}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Example (non-sensitive) inputs\n",
    "income = 75_000\n",
    "debt = 30_000\n",
    "credit_score = 620\n",
    "requested_amount = 250_000\n",
    "\n",
    "query = build_query(income, debt, credit_score, requested_amount)\n",
    "\n",
    "full_input = f'''RUN_METADATA: {json.dumps(run_meta)}\n",
    "\n",
    "SYSTEM_ROLE:\n",
    "{SYSTEM_ROLE}\n",
    "\n",
    "TASK:\n",
    "{query}\n",
    "'''.strip()\n",
    "\n",
    "# Invoke\n",
    "result = graph_agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": full_input}]})\n",
    "final_text = result[\"messages\"][-1].content\n",
    "\n",
    "print(\"=== RAW AGENT OUTPUT ===\")\n",
    "print(final_text[:2000])\n",
    "\n",
    "# Parse JSON from the agent output, apply HITL routing, and show final structured output\n",
    "parsed = parse_json_from_text(final_text)\n",
    "decision_payload = apply_hitl_policy(parsed)\n",
    "\n",
    "final_output = {**run_meta, **decision_payload}\n",
    "print(\"\\n=== FINAL STRUCTURED OUTPUT ===\")\n",
    "print(json.dumps(final_output, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e48326",
   "metadata": {},
   "source": [
    "## 7) Reliability - Feedback Layer (decision records + backtesting stub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9e02547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved decision record to: decision_records.jsonl\n"
     ]
    }
   ],
   "source": [
    "DECISION_LOG_PATH = \"decision_records.jsonl\"\n",
    "\n",
    "def append_decision_record(record: Dict[str, Any], path: str = DECISION_LOG_PATH) -> None:\n",
    "    with open(path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(record) + \"\\n\")\n",
    "\n",
    "append_decision_record(final_output)\n",
    "print(f\"Saved decision record to: {DECISION_LOG_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6c6aec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"n_records\": 1,\n",
      "  \"review_rate\": 0.0,\n",
      "  \"avg_risk_score\": 0.0,\n",
      "  \"note\": \"Replace with 12-month backtesting + expected vs actual dashboard metrics.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def load_last_n(path: str, n: int = 50) -> List[Dict[str, Any]]:\n",
    "    try:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            lines = f.readlines()[-n:]\n",
    "        return [json.loads(line) for line in lines if line.strip()]\n",
    "    except FileNotFoundError:\n",
    "        return []\n",
    "\n",
    "def backtest_stub(records: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "    '''\n",
    "    MVP placeholder:\n",
    "    Production: join with outcomes and compute FN/FP/Recall/Precision over last 12 months.\n",
    "    Here: summarize review rate + average risk score.\n",
    "    '''\n",
    "    if not records:\n",
    "        return {\"error\": \"no_records\"}\n",
    "\n",
    "    review_rate = sum(1 for r in records if r.get(\"decision\") == \"Needs Human Review\") / len(records)\n",
    "    avg_risk = sum(float(r.get(\"risk_score\", 0.0)) for r in records) / len(records)\n",
    "    return {\n",
    "        \"n_records\": len(records),\n",
    "        \"review_rate\": review_rate,\n",
    "        \"avg_risk_score\": avg_risk,\n",
    "        \"note\": \"Replace with 12-month backtesting + expected vs actual dashboard metrics.\"\n",
    "    }\n",
    "\n",
    "recent = load_last_n(DECISION_LOG_PATH, n=50)\n",
    "print(json.dumps(backtest_stub(recent), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bef683",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
